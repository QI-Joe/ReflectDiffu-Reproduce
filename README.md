# ğŸ¤– ReflectDiffu-Reproduce

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **Reproduction implementation for:** *ReflectDiffu: Reflect between Emotion-intent Contagion and Mimicry for Empathetic Response Generation via a RL-Diffusion Framework*

This repository provides a complete implementation for training and evaluating the ReflectDiffu model, which generates empathetic responses by combining emotion-intent contagion with reinforcement learning and diffusion frameworks.

## Train file explination

### å…¶å®ƒæ¨¡å‹ç»„ä»¶ä»‹ç»
[Emotion Contagionéƒ¨åˆ†ä»‹ç»](src/emotion_contagion/README.md) \
[ERAéƒ¨åˆ†ä»‹ç»](src/era/README.md)\
[Intent Twiceéƒ¨åˆ†ä»‹ç»](src/intent_twice/README.md)

### æ¨¡å‹æ•´ä½“è®­ç»ƒä¸ `model_intergration.py` ä¸­ `ReflectDiffu.forward` è¯´æ˜

æœ¬èŠ‚è¯¦ç»†è§£é‡Šè®­ç»ƒä¸»æµç¨‹ä¸­å„ç»„ä»¶çš„è¾“å…¥ / è¾“å‡ºå¼ é‡ã€å½¢çŠ¶ã€ä»¥åŠå®ƒä»¬ä¹‹é—´çš„è¡”æ¥ã€‚æºç æ ¸å¿ƒè°ƒç”¨é“¾ï¼š

`train.py -> ReflectDiffu.initialize_all() -> è¿­ä»£ batches -> train_step() -> model.forward(batch)`ã€‚

> å„å­æ¨¡å—å†…éƒ¨æ›´ç»†çš„ç»“æ„ã€å…¬å¼ä¸èƒŒæ™¯å¯å‚è€ƒå¯¹åº”å­ç›®å½•å†…çš„ READMEï¼š
> - æƒ…æ„Ÿä¼ æŸ“ç¼–ç ï¼ˆEmotion Contagionï¼‰ï¼š`src/emotion_contagion/README.md`
> - ERAï¼ˆæƒ…æ„ŸåŸå› æ ‡ç­¾/æ¨ç†ï¼Œå¯é€‰ï¼‰ï¼š`src/era/README.md`
> - Intent Twiceï¼ˆRL + Diffusion æ„å›¾äºŒæ¬¡æœºåˆ¶ï¼‰ï¼š`src/intent_twice/README.md`

#### 1. æ‰¹æ•°æ®å‡†å¤‡ `_prepare_batch_data`
ä» `batches`ï¼ˆç”± `_init_data_loader` ç”Ÿæˆï¼‰ä¸­å–å‡ºä¸€ä¸ªå…ƒç´ ï¼Œæ„é€ æˆè®­ç»ƒæ‰€éœ€å¼ é‡ï¼š

| å­—æ®µ | å½¢çŠ¶ / ç±»å‹ | å«ä¹‰ | æ¥æº |
|------|-------------|------|------|
| `tokens` | `[B, L]` LongTensor | ç”¨æˆ·è¾“å…¥ token id åºåˆ— | ç”¨æˆ·ä¾§ `user_data['input_ids']` |
| `label_ids` | `[B, L]` LongTensor | æ¯ä¸ª token çš„æƒ…æ„Ÿ/åŸå› æ ‡ç­¾ id | `user_data['label_ids']` |
| `attention_mask` | `[B, L]` LongTensor | 1=æœ‰æ•ˆ,0=Padding | `user_data['attention_mask']` |
| `h_tilde` | `None` æˆ– `[B,L,D]` | ERA ç¼–ç ç‰¹å¾ï¼ˆå½“å‰å…³é—­ä¸º Noneï¼‰ | è‹¥å¼€å¯ ERA æ¨¡å— |
| `p_intent` | `List[List[float]]` (é•¿åº¦ Bï¼Œæ¯ä¸ªå†…éƒ¨ç»´åº¦â‰ˆæ„å›¾è¯è¡¨å¤§å°) | å¤–éƒ¨æ„å›¾é¢„æµ‹åˆ†å¸ƒï¼ˆEmpHi / é¢„è®­ç»ƒæ„å›¾æ¨¡å‹ï¼‰ | `get_intent_distribution` |
| `emotion_id` | `[B]` LongTensor | ä¸»å¯¼æƒ…æ„Ÿç±»åˆ« idï¼ˆç”¨äºåˆ†ç±»ç›‘ç£ï¼‰ | åŒ¹é…æ˜ å°„ `matched_emotion` |
| `trg_input_ids` | `[B, T_dec]` LongTensor | è§£ç å™¨ teacher forcing è¾“å…¥ï¼ˆå·¦ç§»å¹¶åŠ  BOSï¼‰ | ç”±å“åº”åºåˆ—å¤„ç† |
| `gold_ids` | `[B, T_dec]` LongTensor | è§£ç ç›®æ ‡ï¼ˆå« PADï¼‰ | å“åº”æˆªæ–­/å¡«å…… |
| `tgt_key_padding_mask` | `[B, T_dec]` Bool/Long | è§£ç ç«¯ padding mask | æ„é€ æ—¶ (token==pad) |
| `src_ids_from_encoder` | `[B, L]` LongTensor | å¤åˆ¶æœºåˆ¶ï¼ˆPointerï¼‰æº tokens | å¤ç”¨ encoder è¾“å…¥ |
| `responses_tokens` | `List[str]` | æ–‡æœ¬å½¢å¼ä»…ç”¨äºæ—¥å¿— | response tokens æ‹¼æ¥ |

> å¤‡æ³¨ï¼š`B`=batch sizeï¼Œ`L`=ç¼–ç åºåˆ—æœ€å¤§é•¿åº¦ï¼Œ`T_dec`=è§£ç åºåˆ—æœ€å¤§é•¿åº¦ã€‚

#### 2. æƒ…æ„Ÿä¼ æŸ“ç¼–ç å™¨é˜¶æ®µ
è°ƒç”¨ï¼š
```python
enc_out = self.encoder.forward(tokens, label_ids, attention_mask, h_tilde)
```
ä¸»è¦è¾“å‡ºï¼š
| åç§° | å½¢çŠ¶ | è¯´æ˜ |
|------|------|------|
| `H` | `[B, L, D]` | ç¼–ç åä¸Šä¸‹æ–‡åºåˆ—éšè—è¡¨ç¤º |
| `Q` | `[B, D]` | å¯¹åºåˆ—æ± åŒ–/èåˆåçš„å…¨å±€æƒ…æ„Ÿè¯­ä¹‰å‘é‡ï¼ˆåç»­æ„å›¾ã€å¯¹è¯æƒ…æ„Ÿäº¤äº’æ ¸å¿ƒï¼‰|
| `P` | `[B, N_emotion]` | æƒ…æ„Ÿç±»åˆ«æ¦‚ç‡åˆ†å¸ƒ |

æŸå¤±ï¼š
| åç§° | å½¢çŠ¶ | è¯´æ˜ |
|------|------|------|
| `ntx_loss` | æ ‡é‡ | å¯¹æ¯”å­¦ä¹ /æ¸©åº¦åŒ–åˆ†å¸ƒæŸå¤±ï¼ˆæ¥è‡ª encoder å†…éƒ¨ `loss` æ–¹æ³•ï¼‰|
| `Lce_loss` | æ ‡é‡ | æƒ…æ„Ÿå¤šç±»äº¤å‰ç†µï¼ˆ`ce_loss_for_emotion`ï¼‰|
| `Lem` | æ ‡é‡ | ä¸Šè¿°äºŒè€…æ±‚å’Œï¼š`Lem = ntx_loss + Lce_loss` |

#### 3. è¯­ä¹‰æ„å›¾åˆ†å¸ƒ + Intent Twice é›†æˆ
è¯­ä¹‰æ‰“åˆ†ï¼š
```python
P_semantic, _ = self.semantic_scorer(Q)   # [B, N_intent]
enc_out['P_semantic'] = P_semantic
```

éšåè°ƒç”¨æ„å›¾äºŒæ¬¡æ¨¡å—ï¼š
```python
it_out = self.it_module.forward(encoder_out=enc_out, intent_out={'p_intent': p_intent})
```
æ„å›¾äºŒæ¬¡æ¨¡å—ï¼ˆå†…éƒ¨å« EMU + Policy + èåˆï¼‰æ ¸å¿ƒäº§ç‰©ï¼š
| åç§° | å½¢çŠ¶ | å«ä¹‰ |
|------|------|------|
| `Emofused` | `[B, L_fuse, D]` æˆ– `[B, D]` | æ­£è´Ÿæƒ…æ„Ÿæ„å›¾æ–¹å‘èåˆåçš„æƒ…æ„Ÿ-æ„å›¾è¡¨ç¤ºï¼ˆè‹¥ä¸º `[B,D]` ä¼šåœ¨åé¢å‡ç»´ï¼‰|
| `Ltwice` | æ ‡é‡ | Intent Twice å­æ¨¡å—æ€»æŸå¤±ï¼ˆKL + æ„å›¾æ ¡æ­£ CE + å¯é€‰ç­–ç•¥é¡¹ï¼‰|
| ï¼ˆå¯èƒ½è¿˜åŒ…å«ï¼‰`Emopos/Emoneg` | `[B, D]` | æ­£/è´Ÿåˆ†æ”¯æƒ…æ„Ÿæ–¹å‘ï¼ˆè‹¥åœ¨å†…éƒ¨å­—å…¸æš´éœ²ï¼‰|

#### 4. å“åº”è§£ç å™¨é˜¶æ®µï¼ˆPointer-Generatorï¼‰
å‡†å¤‡ï¼šå¦‚æœ `Emofused` æ˜¯ `[B,D]` åˆ™ `unsqueeze(1)` â†’ `[B,1,D]`ã€‚

æºç è°ƒç”¨ï¼š
```python
dec_out = self.decoder_with_loss(
    trg_input_ids, emofused=Emofused, src_token_ids=src_ids_from_encoder,
    gold_ids=gold_ids, tgt_key_padding_mask=tgt_key_padding_mask)
```

è¾“å‡ºï¼ˆ`PaperCompliantDecoderWithLoss`ï¼‰ï¼š
| åç§° | å½¢çŠ¶ | è¯´æ˜ |
|------|------|------|
| `Pw` | `[B, T_dec, V_ext]` | æœ€ç»ˆè¯åˆ†å¸ƒï¼ˆæ··åˆç”Ÿæˆ+å¤åˆ¶ï¼‰|
| `Pgen` | `[B, T_dec, V_ext]` | çº¯ç”Ÿæˆ softmax åˆ†å¸ƒ |
| `Pcopy` | `[B, T_dec, V_ext]` | æ ¹æ®æ³¨æ„åŠ›æ•£å°„åçš„å¤åˆ¶åˆ†å¸ƒ |
| `p_mix` | `[B, T_dec, 1]` | Pointer-Generator é—¨ï¼šç”Ÿæˆ vs å¤åˆ¶ æƒé‡ |
| `hidden` | `[B, T_dec, D]` | è§£ç éšè—çŠ¶æ€ |
| `attn_weights` | `[B, T_dec, L_emof]` | å¯¹ `Emofused`ï¼ˆä½œä¸ºå”¯ä¸€ KVï¼‰ çš„æ³¨æ„åŠ›æƒé‡ |
| `context_vector` | `[B, T_dec, D]` | æ³¨æ„åŠ›åŠ æƒä¸Šä¸‹æ–‡å‘é‡ |
| `loss` | æ ‡é‡ | è§£ç æ€»æŸå¤±ï¼ˆCE + coverage*ç³»æ•°ï¼‰|
| `ce_loss` | æ ‡é‡ | äº¤å‰ç†µéƒ¨åˆ† |
| `coverage_loss` | æ ‡é‡ | è¦†ç›–æŸå¤±ï¼ˆè‹¥å¯ç”¨ï¼‰|

å®šä¹‰å“åº”æŸå¤±ï¼š`Lres = dec_out['loss']`ã€‚

#### 5. Forward æœ€ç»ˆè¿”å›å­—å…¸
`ReflectDiffu.forward` è¿”å›ï¼š
| Key | å½¢çŠ¶ | è¯­ä¹‰ |
|-----|------|------|
| `Lem` | æ ‡é‡ | æƒ…æ„Ÿç¼–ç ç›¸å…³æŸå¤± (å¯¹æ¯” + CE) |
| `Ltwice` | æ ‡é‡ | æ„å›¾äºŒæ¬¡æ¨¡å—æŸå¤± |
| `Lres` | æ ‡é‡ | è§£ç å™¨æŸå¤± |
| `H` | `[B, L, D]` | ç¼–ç çš„ä¸Šä¸‹æ–‡åºåˆ—ç‰¹å¾ |
| `Q` | `[B, D]` | å…¨å±€æƒ…æ„Ÿè¯­ä¹‰å‘é‡ï¼ˆä¸‹æ¸¸è¯­ä¹‰/æ„å›¾äº¤äº’æ ¸å¿ƒï¼‰|
| `P` | `[B, N_emotion]` | æƒ…æ„Ÿç±»åˆ«åˆ†å¸ƒ |
| `Emofused` | `[B, L_fuse, D]` | æƒ…æ„Ÿ+æ„å›¾èåˆè¡¨ç¤ºï¼ˆä¾›è§£ç  Cross-Attnï¼‰|
| `decoder_output` | dict | ä¸Šæ–‡åˆ—å‡ºçš„æ‰€æœ‰è§£ç é˜¶æ®µä¸­é—´äº§ç‰© |
| `batch_data` | dict | æœ¬æ¬¡ forward è¾“å…¥çš„åŸå§‹/è¡ç”Ÿæ‰¹æ•°æ®ï¼ˆä¾¿äºè°ƒè¯•æˆ–æ—¥å¿—ï¼‰|

> è®­ç»ƒä¸­è”åˆæŸå¤±ï¼ˆ`train_step` å†…ï¼‰ï¼š`joint_loss = Î´Â·Lem + Î¶Â·Ltwice + Î·Â·Lres`ï¼Œå¯¹åº”å‘½ä»¤è¡Œæˆ–é…ç½®ä¸­çš„ `--delta / --zeta / --eta` æƒé‡ã€‚

#### 6. ç»„ä»¶ååŒæ€»ç»“
1. Data Processorï¼šæ¸…æ´—å¹¶å¯¹é½ç”¨æˆ·/å›åº”ï¼Œäº§ç”Ÿ token ids ä¸æ ‡ç­¾ã€‚ 
2. Emotion Contagion Encoderï¼šå»ºæ¨¡ä¸Šä¸‹æ–‡æƒ…æ„ŸåŠ¨æ€ â†’ è¾“å‡ºåºåˆ—è¡¨ç¤º `H` ä¸å…¨å±€è¡¨ç¤º `Q` åŠæƒ…æ„Ÿåˆ†å¸ƒ `P`ã€‚ 
3. Semantic Scorerï¼šåŸºäº `Q` é¢å¤–ç”Ÿæˆè¯­ä¹‰æ„å›¾åˆ†å¸ƒ `P_semantic` ä¸å¤–éƒ¨æ„å›¾åˆ†å¸ƒç»“åˆã€‚ 
4. Intent Twice (EMU + Policy)ï¼šåˆ©ç”¨æ­£/è´Ÿåˆ†æ”¯æ‰©æ•£ + æ„å›¾å€™é€‰ç­–ç•¥ï¼Œæ ¡æ­£å¹¶èåˆä¸º `Emofused`ï¼Œæä¾›æƒ…æ„Ÿ-æ„å›¾ä¸€è‡´æ€§ã€‚ 
5. Response Decoderï¼šä»…ä»¥ `Emofused` ä¸ºè·¨æ³¨æ„é”®å€¼è¿›è¡Œå—æ§ç”Ÿæˆï¼›Pointer-Generator ç»“åˆå¤åˆ¶ä»¥æå‡å¯å¤åˆ¶å®ä½“/æƒ…æ„Ÿè¯ã€‚ 
6. Loss Aggregationï¼šä¸‰å—æŸå¤±åŠ æƒåˆæˆï¼Œæ”¯æŒçµæ´»è°ƒå‚ï¼›å¯æ‰©å±•åŠ å…¥ ERA æˆ–ç­–ç•¥æŸå¤±æƒé‡ã€‚ 

#### 7. å¿«é€Ÿå®šä½æ’æŸ¥å»ºè®®
| ç°è±¡ | é¦–å…ˆæŸ¥çœ‹ |
|------|----------|
| è§£ç é‡å¤ | `coverage_loss` æ˜¯å¦å¯ç”¨ï¼›`p_mix` æ˜¯å¦é•¿æ—¶é—´æ¥è¿‘ 0 or 1 |
| æƒ…æ„Ÿä¸ç¨³å®š | `P` åˆ†å¸ƒæ˜¯å¦å¡Œé™·ï¼›`Lem` æ˜¯å¦ä¸‹é™ |
| æ„å›¾æœªä½“ç° | `Emofused` ä¸ `Emopos/Emoneg` æ˜¯å¦å‡ ä¹æ— å·®å¼‚ï¼›`Ltwice` æ˜¯å¦é•¿æœŸä¸º 0 |
| è¾“å‡ºé£æ ¼å•ä¸€ | æ£€æŸ¥å¤–éƒ¨ `p_intent` æ˜¯å¦æ’å®šï¼›ç­–ç•¥é‡‡æ ·æ¸©åº¦/æ‰©æ•£æ­¥æ•° |

---
é€šè¿‡ä¸Šè¿°åˆ†å±‚ç»“æ„ä¸å¼ é‡æµå‘ï¼Œå¯ä»¥å¿«é€Ÿç†è§£ä»åŸå§‹å¯¹è¯è¾“å…¥åˆ°æœ€ç»ˆ empathetic response ç”Ÿæˆçš„å…¨é“¾è·¯ï¼šæƒ…æ„Ÿä¸æ„å›¾åœ¨ç¼–ç é˜¶æ®µè€¦åˆï¼Œå†ç» RL-Diffusion åŒåˆ†æ”¯å¼ºåŒ–åï¼Œåœ¨è§£ç é˜¶æ®µè¢«é›†ä¸­ç”¨äºç”Ÿæˆæ§åˆ¶ã€‚è‹¥éœ€è¦æ·±å…¥å†…éƒ¨å…¬å¼æˆ–ç»†èŠ‚ï¼Œè¯·è·³è½¬å„è‡ªå­ç›®å½• READMEã€‚


## ğŸš€ Quick Start

## Final Result Fast Review
You can review current the best result in
```
./output/eval_logs/
```

### Evaluate Pre-trained Model

Run the best pre-trained model with comprehensive evaluation metrics:

```bash
python display.py --model_path output/best_model/best_model.pt
```

**Output:** Evaluation results will be saved in `output/eval_logs/`

**Metrics Evaluated:**
- ğŸ“Š **Relevance**: BLEU-1/2/3/4, BARTScore
- ğŸ¯ **Informativeness**: Perplexity (PPL), Distinct-1/2

### Custom Evaluation

```bash
# Evaluate with custom parameters
python display.py --model_path path/to/model.pt --data_path dataset/test.pkl --max_samples 200

# Use specific device
python display.py --model_path output/best_model/best_model.pt --device cuda
```

## ğŸ—ï¸ Training Setup

### 1. ğŸ“ Data Preparation

Place your data files in the `dataset/` directory:

```
dataset/
â”œâ”€â”€ emotion_labels_user_response.pkl  # Training data
â””â”€â”€ emotion_labels_test.pkl           # Test data
```

**Data Format:**
```python
[
    [
        [user_data, response_data]
    ],
    [
        [user_data1, response_data1]
    ],
    # ... more conversation pairs
]
```

**Data Structure:**
- `user_data`: `[(word1, <em>), (word2, <noem>), ...]`
- `response_data`: `[(word1, <em>), (word2, <noem>), ...]`

### 2. ğŸ§  EmpHi Intent Prediction Setup

Download the required EmpHi models and reflect-Diffu best models from [Google Drive](https://drive.google.com/drive/folders/148Ftrh_mH8y7_yOap2h9CmMXxYn4cgc0?usp=drive_link) and organize as follows:

```
pre-trained/
â”œâ”€â”€ intent_prediction/
â”‚   â””â”€â”€ paras.pkl          # Intent prediction parameters
â””â”€â”€ model/
    â””â”€â”€ model              # Pre-trained EmpHi model

output
â””â”€â”€ best_model/
    â””â”€â”€ best_model.pt      # trained best model
```

### 3. ğŸš‚ Start Training

```bash
python train.py
```

## ğŸ“Š Evaluation Metrics

### Relevance Metrics
- **BLEU-1/2/3/4**: N-gram overlap with reference responses
- **BARTScore**: Semantic similarity using BART model
- **Brevity Penalty**: Length normalization factor

### Informativeness Metrics
- **Perplexity (PPL)**: Language model confidence (lower is better)
- **Distinct-1/2**: Lexical diversity at unigram/bigram level (higher is better)

## ğŸ› ï¸ Dependencies

Key requirements:
- Python 3.10
- PyTorch 2.0+
- transformers
- sacrebleu
- torcheval (optional, for optimized perplexity computation)

Install dependencies:
```bash
pip install -r requirement
```

## ğŸ“ Usage Examples

### Basic Evaluation
```bash
python display.py --model_path output/best_model/best_model.pt
```

### Training from Scratch
```bash
# Ensure data is in dataset/ and pre-trained models are in pre-trained/
python train.py
```

### Custom Evaluation with Specific Parameters
```bash
python display.py \
    --model_path checkpoints/epoch_10.pt \
    --data_path dataset/emotion_labels_test.pkl \
    --max_samples 500 \
    --device cuda
```

## ğŸ“‚ Project Structure

```
ReflectDiffu-Reproduce/
â”œâ”€â”€ src/                           # Source code modules
â”‚   â”œâ”€â”€ emotion_contagion/         # Emotion contagion components
â”‚   â”œâ”€â”€ intent_twice/              # Intent processing modules
â”‚   â””â”€â”€ era/                       # ERA components
â”œâ”€â”€ evaluation/                    # Evaluation scripts
â”‚   â”œâ”€â”€ relevance_evaluation.py    # BLEU & BARTScore evaluation
â”‚   â””â”€â”€ informativeness.py         # Perplexity & Distinct-n evaluation
â”œâ”€â”€ dataset/                       # Training and test data
â”œâ”€â”€ pre-trained/                   # Pre-trained models
â”œâ”€â”€ output/                        # Model outputs and logs
â”‚   â”œâ”€â”€ best_model/               # Best trained model
â”‚   â””â”€â”€ eval_logs/                # Evaluation results
â”œâ”€â”€ display.py                     # Main evaluation script
â”œâ”€â”€ train.py                       # Training script
â””â”€â”€ README.md                      # This file
```

